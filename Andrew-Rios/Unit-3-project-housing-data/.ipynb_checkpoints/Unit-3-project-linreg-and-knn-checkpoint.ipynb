{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Project 3: Linear Regression and KNN - Train/Test Split\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "We've discussed overfitting in the context of bias and variance, and we've touched on some techniques, such as regularization, that are used to avoid overfitting (but haven't practised them yet). In this project we'll review _train/test split_ validation that is a fundamental method for avoiding overfitting. \n",
    "\n",
    "The idea is similar to 'cross-validation' — in fact, it is a type of cross-validation — in that we split the data set into two subsets:\n",
    "* A subset on which to train our model.\n",
    "* A subset on which to test our model's predictions.\n",
    "\n",
    "This serves two useful purposes:\n",
    "* We prevent overfitting by not using all of the data.\n",
    "* We have some remaining data we can use to evaluate our model.\n",
    "\n",
    "While this may seem like a relatively simple idea, **there are some caveats** to putting it into practice. For example, if you are not careful, it is easy to take a non-random split. Suppose we have salary data on technical professionals that is composed of 80 percent data from California and 20 percent data from elsewhere and is sorted by state. If we split our data into 80 percent training data and 20 percent testing data, we might inadvertantly select all the California data to train and all the non-California data to test. In this case we've still overfit on our data set because we did not sufficiently randomize the data.\n",
    "\n",
    "In a situation like this we can use _k-fold cross-validation_, which is the same idea applied to more than two subsets. In particular, we partition our data into $k$ subsets and train on $k-1$ one of them, holding the last slice for testing. We can do this for each of the possible $k-1$ subsets.\n",
    "\n",
    "We will cover Linear Regression and Knn in this project, with an Enrichment section at the end:\n",
    "<a id=\"home\"></a>\n",
    "1. [Linear Regression - Ames housing data](#lin-reg)\n",
    "2. [Optional: Knn - iris data set](#knn)\n",
    "3. [Optional: Enrichment](#enrichment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Home](#home)\n",
    "\n",
    "<a id=\"lin-reg\"></a>\n",
    "# <font style='color: green'>1) Linear Regression Use Case</font>\n",
    "\n",
    "Ultimately we use a test-training split to compare multiple models on the same data set. This could be comparisons of two linear models or of completely different models on the same data.\n",
    "\n",
    "For your independent practice, fit three different models on the Ames housing data by picking three different subsets of variables. (You could also fit one or more polynomial models, or any other model you'd like, but we haven't covered them.) \n",
    "\n",
    "### Here's What We Will Be Doing:\n",
    "\n",
    "* Working with Ames housing data to predict the value of a home.\n",
    "* Create a test-train split of the data.\n",
    "* Train each of your models on the training data.\n",
    "* Evaluate each of the models on the test data.\n",
    "* Rank the models by how well they score on the testing data set.\n",
    "\n",
    "**Then, try k-folds.**\n",
    "\n",
    "* Try a few different splits of data for the same models.\n",
    "* Perform a k-fold cross-validation and use the cross-validation scores to compare your models. Did this change your rankings?\n",
    "\n",
    "**Be sure to provide interpretation for your results.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that k-fold cross-validation creates a hold portion of your data set for each iteration of training and validating:\n",
    "\n",
    "![](http://i.imgur.com/0PFrPXJ.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this given task, you will be asked to model the median home price of various houses in Iowa (the Ames housing data set we have come across before). This is a probable use case: we are predicting a continuous, numeric output (price) based on a combination of discrete features.\n",
    "\n",
    "Reminder of the dataset: [Ames house price data on Kaggle](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data dictionary (taken from Kaggle)\n",
    "\n",
    "+ SalePrice - the property's sale price in dollars. This is the target variable that you're trying to predict.\n",
    "+ MSSubClass: The building class\n",
    "+ MSZoning: The general zoning classification\n",
    "+ LotFrontage: Linear feet of street connected to property\n",
    "+ LotArea: Lot size in square feet\n",
    "+ Street: Type of road access\n",
    "+ Alley: Type of alley access\n",
    "+ LotShape: General shape of property\n",
    "+ LandContour: Flatness of the property\n",
    "+ Utilities: Type of utilities available\n",
    "+ LotConfig: Lot configuration\n",
    "+ LandSlope: Slope of property\n",
    "+ Neighborhood: Physical locations within Ames city limits\n",
    "+ Condition1: Proximity to main road or railroad\n",
    "+ Condition2: Proximity to main road or railroad (if a second is present)\n",
    "+ BldgType: Type of dwelling\n",
    "+ HouseStyle: Style of dwelling\n",
    "+ OverallQual: Overall material and finish quality\n",
    "+ OverallCond: Overall condition rating\n",
    "+ YearBuilt: Original construction date\n",
    "+ YearRemodAdd: Remodel date\n",
    "+ RoofStyle: Type of roof\n",
    "+ RoofMatl: Roof material\n",
    "+ Exterior1st: Exterior covering on house\n",
    "+ Exterior2nd: Exterior covering on house (if more than one material)\n",
    "+ MasVnrType: Masonry veneer type\n",
    "+ MasVnrArea: Masonry veneer area in square feet\n",
    "+ ExterQual: Exterior material quality\n",
    "+ ExterCond: Present condition of the material on the exterior\n",
    "+ Foundation: Type of foundation\n",
    "+ BsmtQual: Height of the basement\n",
    "+ BsmtCond: General condition of the basement\n",
    "+ BsmtExposure: Walkout or garden level basement walls\n",
    "+ BsmtFinType1: Quality of basement finished area\n",
    "+ BsmtFinSF1: Type 1 finished square feet\n",
    "+ BsmtFinType2: Quality of second finished area (if present)\n",
    "+ BsmtFinSF2: Type 2 finished square feet\n",
    "+ BsmtUnfSF: Unfinished square feet of basement area\n",
    "+ TotalBsmtSF: Total square feet of basement area\n",
    "+ Heating: Type of heating\n",
    "+ HeatingQC: Heating quality and condition\n",
    "+ CentralAir: Central air conditioning\n",
    "+ Electrical: Electrical system\n",
    "+ 1stFlrSF: First Floor square feet\n",
    "+ 2ndFlrSF: Second floor square feet\n",
    "+ LowQualFinSF: Low quality finished square feet (all floors)\n",
    "+ GrLivArea: Above grade (ground) living area square feet\n",
    "+ BsmtFullBath: Basement full bathrooms\n",
    "+ BsmtHalfBath: Basement half bathrooms\n",
    "+ FullBath: Full bathrooms above grade\n",
    "+ HalfBath: Half baths above grade\n",
    "+ Bedroom: Number of bedrooms above basement level\n",
    "+ Kitchen: Number of kitchens\n",
    "+ KitchenQual: Kitchen quality\n",
    "+ TotRmsAbvGrd: Total rooms above grade (does not include bathrooms)\n",
    "+ Functional: Home functionality rating\n",
    "+ Fireplaces: Number of fireplaces\n",
    "+ FireplaceQu: Fireplace quality\n",
    "+ GarageType: Garage location\n",
    "+ GarageYrBlt: Year garage was built\n",
    "+ GarageFinish: Interior finish of the garage\n",
    "+ GarageCars: Size of garage in car capacity\n",
    "+ GarageArea: Size of garage in square feet\n",
    "+ GarageQual: Garage quality\n",
    "+ GarageCond: Garage condition\n",
    "+ PavedDrive: Paved driveway\n",
    "+ WoodDeckSF: Wood deck area in square feet\n",
    "+ OpenPorchSF: Open porch area in square feet\n",
    "+ EnclosedPorch: Enclosed porch area in square feet\n",
    "+ 3SsnPorch: Three season porch area in square feet\n",
    "+ ScreenPorch: Screen porch area in square feet\n",
    "+ PoolArea: Pool area in square feet\n",
    "+ PoolQC: Pool quality\n",
    "+ Fence: Fence quality\n",
    "+ MiscFeature: Miscellaneous feature not covered in other categories\n",
    "+ MiscVal: $Value of miscellaneous feature\n",
    "+ MoSold: Month Sold\n",
    "+ YrSold: Year Sold\n",
    "+ SaleType: Type of sale\n",
    "+ SaleCondition: Condition of sale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries and data we'll need, and set up our feature matrix (Xs) and response vector (y)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "houses = pd.read_csv('data/iowa_houses.csv')\n",
    "\n",
    "# create feature matrix (X)\n",
    "feature_cols = houses.columns.drop(['SalePrice'])\n",
    "X = houses[feature_cols]\n",
    "\n",
    "# create response vector (y)\n",
    "y = houses.SalePrice\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Clean Up Data and Perform Exporatory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Boston data is from scikit-learn, so it ought to be pretty clean, but we should always perform exploratory data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploratory data analysis.\n",
    "\n",
    "# Include: total nulls, index, data types, shape, summary statistics, and the number of unique values for each column\n",
    "\n",
    "# Remember to handle null cells and columns with non-numeric data in them. Document the decisions you have made and\n",
    "# why you have made them.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using `scikit-learn` Linear Regression\n",
    "\n",
    "### 2. Pick 3-4 predictors (e.g. GarageQual, GrLivArea, etc...) that you will use to predict our target variable, SalePrice.\n",
    "Score and plot your predictions. What do these results tell us?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Try 70/30 and 90/10 train/test splits (70% of the data for training - 30% for testing, then 90% for training - 10% for testing)\n",
    "Score and plot. How do your metrics change? What does this tell us about the size of training/testing splits?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Use k-fold cross validation varying the number of folds from 5 to 10\n",
    "What seems optimal? How do your scores change? What is the variance like? Try different folds to get a sense of how this impacts your score. What are the tradeoffs associated with choosing the number of folds?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Home](#home)\n",
    "\n",
    "<a id=\"knn\"></a>\n",
    "# <font style='color: green'>2) Optional: KNN Practise</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the iris data into a DataFrame\n",
    "url = 'http://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'\n",
    "\n",
    "col_names = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species']\n",
    "iris = pd.read_csv(url, header=None, names=col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.head()\n",
    "\n",
    "# Increase the default figure and font sizes for easier viewing\n",
    "plt.rcParams['figure.figsize'] = (6, 4)\n",
    "plt.rcParams['font.size'] = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom colormap\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "cmap_bold = ListedColormap(['#FF0000', '#00FF00', '#0000FF'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map each iris species to a number\n",
    "# Let's use Iris-setosa':0, 'Iris-versicolor':1, 'Iris-virginica':2 and create a column called 'species_num'\n",
    "\n",
    "# Create a scatterplot of PETAL LENGTH versus PETAL WIDTH and color by SPECIES\n",
    "\n",
    "# Create a scatterplot of SEPAL LENGTH versus SEPAL WIDTH and color by SPECIES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Classification of the Iris Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create your feature matrix \"X\"\n",
    "This will be all species measurements (sepal length, petal width, etc...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create your target vector \"y\"\n",
    "This will be the species type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Use of Train-Test-Split\n",
    "Split your data in to train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import KNN From `scikit-learn` and Instantiate a Model With One Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the Accuracy\n",
    "Train your model using the training set then use the test set to determine the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Model With Five Neighbors. Did it Improve?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Looped Function That Will Check All Levels of Various Neighbors and Calculate the Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus: According to `scikit-learn` Documentation, What is `knn.predict_proba(X_new)` Going to Do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Home](#home)\n",
    "\n",
    "<a id=\"enrichment\"></a>\n",
    "# <font style='color: green'>3) Optional: Enrichment</font>\n",
    "_Everything beyond this point is enrichment and examples using Statsmodels for linear regression._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Using the Statsmodels Formula\n",
    "\n",
    "Adapt the formula example using your metrics. We will review this implementation in class. Here is a reference to consider. The workflow is the same, but the syntax is a little different. We want to get accustomed to the formula syntax because we will be using them a lot more with regressions. The results should be comparable to scikit-learn's regression models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, format our data in a DataFrame\n",
    "\n",
    "df = pd.read_csv('data/iowa_houses.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up our new statsmodel.formula handling model\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# You can easily swap these out to test multiple versions/different formulas\n",
    "formulas = {\n",
    "    \"case1\": \"SalePrice ~ GrLivArea + OverallQual + LotArea - 1\", # - 1 = remove intercept\n",
    "    \"case2\": \"SalePrice ~ GrLivArea + LotFrontage\",\n",
    "    \"case3\": \"SalePrice ~ LotFrontage + OverallQual\"\n",
    "}\n",
    "\n",
    "model = smf.ols(formula=formulas['case1'], data=df)\n",
    "result = model.fit()\n",
    "\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus Challenge #1:\n",
    "\n",
    "Can you optimize your R2, selecting the best features and using either test-train split or k-folds?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus Challenge #2:\n",
    "\n",
    "Given a combination of predictors, can you find another response variable that can be accurately predicted through the exploration of different predictors in this data set?\n",
    "\n",
    "_Tip: Check out pairplots, coefficients, and Pearson scores._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out variable relations\n",
    "import seaborn as sns\n",
    "\n",
    "sns.pairplot(X);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out Pearson scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus Challenge #3 /DEMO: Up for an additional challenge? Try again, this time using the `patsy` library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import patsy\n",
    "\n",
    "# Add response to the core DataFrame\n",
    "df['SalePrice'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split #If you didn't import it earlier, do so now\n",
    "\n",
    "# Easily change your variable predictors without reslicing your DataFrame\n",
    "y, X = patsy.dmatrices(\"SalePrice ~ GrLivArea + OverallQual + LotArea\", data=df, return_type=\"dataframe\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=.7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Rerun your model, iteratively changing your variables and train_size from the previous cell\n",
    "\n",
    "lm = LinearRegression()\n",
    "model = lm.fit(X_train, y_train)\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "print(\"R^2 Score: {}\".format(metrics.r2_score(y_test, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "at_Lab_IT_Frameworks",
   "language": "python",
   "name": "at_lab_it_frameworks"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
